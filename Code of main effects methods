library(easypackages)
libraries("openxlsx","neuralnet","NeuralNetTools","ggpmisc",
          "Rcpp","RSNNS","psych","forcats","ggplot2","gridExtra")
mydata <- read.xlsx(file.choose())
# *********** Identify the following parameters before starting **** 
RD <- 3   # Number of trials for random data
RW <- 3    # Number of trials for random weights
Runs <- 3  # Number of best runs of random data and random weights
# *******************************************************************
Inp <- ncol(mydata) - 1
Nr_of_int <- Inp  * (Inp - 1)/2
NrHidden <- round(Inp * 1.6, 0)
partition <- 0.75  #** partitioning ratio of data into train and test
err <- array(0, dim = c(RD, RW))
indx <- array(0, dim = c(partition * nrow(mydata), RD))
IHW <- array(0, dim = c(Inp + 1, NrHidden, RD, RW))
IHSW <- array(0, dim = c(Inp + 1, NrHidden, RD, RW))
HOW <- array(0, dim = c(NrHidden + 1, RD, RW))
TrNrmse <- array(0, dim = c(RD, RW))
TeNrmse <- array(0, dim = c(RD, RW))
trainIndex <- sample(1:nrow(mydata), partition * nrow(mydata))
RN <- nrow(mydata) - length(trainIndex) # row number of test data
nn_Teoutput <- array(0, dim = c(RN, RD, RW))
nn_Troutput <- array(0, dim = c(length(trainIndex), RD, RW))
tableMS <- as.data.frame(matrix(nrow = 1, ncol = (ncol(mydata) - 1)))
GAM <- as.data.frame(matrix(nrow = 1, ncol = (ncol(mydata) - 1)))
IGAM <- as.data.frame(matrix(nrow = 1, ncol = (ncol(mydata) - 1)))
tableGW <- as.data.frame(matrix(nrow = 1, ncol = (ncol(mydata) - 1)))
tableCW <- as.data.frame(matrix(nrow = 1, ncol = (ncol(mydata) - 1)))
for (R in 1:Runs) {
  for (i in 1:RD) {
    trainingIndex <- sample(1:nrow(mydata), partition * nrow(mydata))
    indx[, i] <- trainingIndex
    trainingData <- data.frame(round(normalizeData(mydata[indx[, i], ], "0_1"), 4))
    testingData <- data.frame(round(normalizeData(mydata[-indx[, i], ], "0_1"), 4))
    names(trainingData) <- colnames(mydata)
    names(testingData) <- colnames(mydata)
    Y_trainData <- normalizeData(mydata[indx[, i], ncol(mydata)], "0_1")
    Y_testData <- normalizeData(mydata[-indx[, i], ncol(mydata)], "0_1")
    for (j in 1:RW) {
      y <- colnames(trainingData[ncol(mydata)])
      x <- colnames(trainingData[-ncol(mydata)])
      formla <- as.formula(paste(y, paste(x, collapse = " + "), sep = " ~ "))
      nn <- neuralnet(formla, data = trainingData, algorithm = "backprop", threshold = 0.01, learningrate = 0.01, 
                      hidden = NrHidden, act.fct = "logistic", linear.output = F)
      # ******** training data ***************
      nn_Trpredict <- neuralnet::compute(nn, trainingData)
      nn_Troutput[, i, j] <- denormalizeData(nn_Trpredict$net.result, getNormParameters(Y_trainData))
      TractualMean <- mean(mydata[indx[, i], ncol(mydata)][[1]])
      TrNrmse[i, j] <- (1/TractualMean) * (sqrt(sum((nn_Troutput[, i, j] - mydata[indx[, i], 
                                                                                  ncol(mydata)])^2)/nrow(trainingData))) * 100
      # ******* testing data *****************
      nn_Tepredict <- neuralnet::compute(nn, testingData)
      nn_Teoutput[, i, j] <- denormalizeData(nn_Tepredict$net.result, getNormParameters(Y_testData))
      TeactualMean <- mean(mydata[-indx[, i], ncol(mydata)][[1]])
      TeNrmse[i, j] <- (1/TeactualMean) * (sqrt(sum((nn_Teoutput[, i, j] - mydata[-indx[, i], 
                                                                                  ncol(mydata)])^2)/nrow(testingData))) * 100
      IHSW[, , i, j] <- nn$startweights[[1]][[1]]
      IHW[, , i, j] <- nn$weights[[1]][[1]]
      HOW[, i, j] <- nn$weights[[1]][[2]]
      err[i, j] <- nn$result.matrix[1, 1]
    }
  }
  min(err)
  min(TeNrmse)
  errpos <- which(TeNrmse == min(TeNrmse), arr.ind = TRUE)
  errbestRow <- errpos[1, 1]  #**** Best random data
  errbestCol <- errpos[1, 2]  #**** best rep for best random data
  # ********** use best weights *******************
  IH_W <- IHW[, , errbestRow, errbestCol]
  HO_W <- HOW[, errbestRow, errbestCol]
  Sqdif_IH <- (IHW[, , errbestRow, errbestCol][-1, ] - IHSW[, , errbestRow, errbestCol][-1, ])^2
  # ************ Olden *****************
  s0<-array(0, dim = c(Inp, NrHidden))
  sums0<-c()
  for (x in 1:Inp) {
    for (y in 1:NrHidden) {
      s0[x,y] <- IH_W[x+1,y] * HO_W[y+1]
    }
  }
  sums0<-apply(s0,1,sum)
  for (d in 1:Inp) {
    tableCW[R, d] <- abs(sums0[d])/sum(abs(sums0))
  }
  # *********** Most Squares method *************
  for (d in 1:Inp) {
    tableMS[R, d] <- round(sum(Sqdif_IH[d, ])/sum(Sqdif_IH), 4)
  }
  # ********** garson algorithm ********
  s1<-array(0, dim = c(Inp, NrHidden))
  sums1<-c()
  for (x in 1:Inp) {
    for (y in 1:NrHidden) {
      s1[x,y] <- abs(IH_W[x+1,y] * HO_W[y+1])
    }
  }
  sums1<-apply(s1,2,sum)
  s2<-array(0, dim = c(Inp, NrHidden))
  sums2<-c()
  for (x in 1:Inp) {
    for (y in 1:NrHidden) {
      s2[x,y] <- abs(s1[x,y]/sums1[y])
    }
  }
  sums2<-apply(s2,1,sum)
  GA<-sums2/sum(sums2)
  
  for (d in 1:Inp) {
    GAM[R, d] <- GA[d]
  }
  # ***** Improved garson *************
  sumi<-apply(abs(IH_W[-1,]),2,sum)
  s3<-array(0, dim = c(Inp, NrHidden))
  for (x in 1:Inp) {
    for (y in 1:NrHidden) {
      s3[x,y] <- abs((IH_W[x+1,y] * HO_W[y+1]))/sumi[y]
    }
  }
  sums3<-apply(s3,1,sum)
  IGA<-sums3/sum(s3)
  
  for (d in 1:Inp) {
    IGAM[R, d] <- IGA[d]
  }
  # Generalized Weights of inputs without interaction
  RGW <- as.data.frame(nn$generalized.weights)
  total <- c()
  for (f in 1:Inp) {
    total[f] <- sum(RGW[,f])
  }
  for (g in 1:Inp) {
    tableGW[R,g] <- abs(total[g])/sum(abs(total))
  }
}
InpVars<-colnames(mydata[-(ncol(mydata))])
names(tableMS) <- InpVars;names(GAM) <- InpVars;names(IGAM) <-InpVars;names(tableGW)<-InpVars
names(tableCW) <-InpVars
# ***************************************************
GWTable<-describe(tableGW, skew = F, ranges = TRUE)# generalized weights
MSTable<-describe(tableMS, skew = F, ranges = TRUE)# most squares
GATable<-describe(GAM, skew = F, ranges = TRUE)# garson algorithm
IGATable<-describe(IGAM, skew = F, ranges = TRUE)# improved garson algorithm
OTable<-describe(tableCW, skew = F, ranges = TRUE)# olden method
GWTable;MSTable;GATable;IGATable;OTable
#******************************
table_list <- list(GWTable,MSTable,GATable,IGATable,OTable)
title_vector <- c("Generalized weights","Most squares algorithm","Garson's algorithm","Improved Garson's algorithm",
                  "Connection weights algorithm")
plot_list <- list()
for (i in 1:length(table_list)) {
  dat=table_list[[i]]
  plot_list[[i]] <- ggplot(dat,aes(x = fct_inorder(rownames(dat)),y = mean, fill = rownames(dat)))+
    geom_bar(stat = "identity", position = "dodge") + 
    geom_errorbar(aes(ymin = mean - se, ymax = mean + se), position = position_dodge(0.5), width = 0.2) +
    xlab(expression(Main~effects)) +
    ylab(expression(Relative~Importance)) +
    theme(axis.text.x=element_text(color = "blue", size = 10, angle = 30, vjust = 0.8, hjust = 0.8)) +
    theme(legend.position="none") + 
    ggtitle(title_vector[i]) + 
    theme(plot.title = element_text(color = "red", size = 12))
}
do.call(grid.arrange,plot_list)
#********************** model performance ********************
trainingData <- data.frame(round(normalizeData(mydata[indx[, errbestRow], ], "0_1"), 4))
testingData <- data.frame(round(normalizeData(mydata[-indx[, errbestRow], ], "0_1"), 4))
names(trainingData) <- colnames(mydata)
names(testingData) <- colnames(mydata)
Y_trainBestData <- normalizeData(mydata[indx[, errbestRow], ncol(mydata)], "0_1")
Y_testBestData <- normalizeData(mydata[-indx[, errbestRow], ncol(mydata)], "0_1")
NN_Output <- nn_Teoutput[, errbestRow, errbestCol]
actual <- denormalizeData(testingData[ncol(mydata)], getNormParameters(Y_testBestData))
dftest<-data.frame(x=actual,y=NN_Output)
ggplot(dftest, aes(x = x, y = y)) + geom_smooth(method="lm") + geom_point() +
  stat_poly_eq(formula = y ~ x,aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               label.x.npc = "left", parse = T)
#**********************  plot neural network **************
plotnet(nn, alpha.val = 0.5, apad_x = 0.8, max_sp = F, pos_col="blue", neg_col = "grey", 
        circle_col = rainbow(NrHidden), bord_col = 'black')
plot(nn,show.weights = F)
